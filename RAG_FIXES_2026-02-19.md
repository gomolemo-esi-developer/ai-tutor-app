# RAG Service Issues - Fixes Applied (2026-02-19)

## Issues Identified

### Issue 1: RAG Service OOM During Audio Processing (ROOT CAUSE)
**Root Cause**: The Whisper "base" model with beam_size=5 requires excessive memory (~800MB-1GB) for 37MB audio files. The RAG process gets OOM-killed before sending the final response, resulting in incomplete response stream.

**Files Changed**:
- `RAG18Nov2025-1/modules/content_processing/file_converter.py` - Audio transcription
- `RAG18Nov2025-1/modules/content_processing/embeddings_generator.py` - Embedding generation

**Fixes**:
1. **Whisper Model**: Changed from "base" (140M params) to "tiny" (39M params)
   ```python
   model = WhisperModel("tiny", device="cpu", compute_type="int8")
   ```

2. **Beam Search**: Changed from `beam_size=5` (beam search) to `beam_size=1` (greedy)
   - Beam search needs O(beam_size) memory - greedy uses minimal memory
   
3. **Voice Activity Detection (VAD)**: Added VAD filter to skip silence
   ```python
   vad_filter=True
   vad_parameters=dict(min_speech_duration_ms=250)
   ```

4. **Garbage Collection**: Added explicit memory cleanup after transcription
   ```python
   del model
   gc.collect()
   ```

5. **Batch Embeddings**: Process embeddings in batches of 50 texts instead of all at once
   ```python
   batch_size = 50
   for i in range(0, len(texts), batch_size):
       batch_embeddings = embeddings_model.embed_documents(batch)
   ```

### Issue 2: "RAG response is not a valid object" 
**Root Cause**: When RAG process crashes before sending final message, the response stream is incomplete. Axios response parsing doesn't handle NDJSON properly with multipart forms. The code was trying to handle streaming but axios buffers responses differently.

**Files Changed**:
- `ai-tutor-app/backend/src/services/rag.service.ts` - `uploadDocument()` method

**Fixes**:
1. Simplified response parsing to use axios default buffering
2. Parse the entire response as text NDJSON instead of streaming
3. Added `validateStatus: () => true` to capture all responses including errors
4. Gracefully handle incomplete responses and partial data
5. Log each processing status for debugging

### Issue 3: Health Check Returns 307 Redirect
**Root Cause**: Health check endpoint path mismatch. FastAPI router with prefix `/health` creates endpoint `/health/` (with trailing slash), but Docker health check was calling `/health` (without trailing slash), causing FastAPI to redirect with 307.

**Files Changed**:
- `Dockerfile.rag`
- `ai-tutor-app/backend/src/services/rag.service.ts`

**Fixes**:
1. Updated Docker health check to use `/health/` with trailing slash
   ```dockerfile
   CMD curl -f http://localhost:8000/health/ || exit 1
   ```

2. Updated RAG service health check method to use `/health/`
   ```typescript
   const response = await this.client.get('/health/', { timeout: 5000 });
   ```

### Issue 4: Request Timeout During Audio Processing
**Root Cause**: Audio file transcription takes time. Backend timeout needs to be sufficient.

**Files Changed**:
- `docker-compose.yml`

**Fixes**:
1. Increased `RAG_TIMEOUT` from 30 seconds to 180 seconds (3 minutes)
   ```yaml
   - RAG_TIMEOUT=180000  # 3 minutes for large file processing
   ```

2. Added `RAG_RETRY_DELAY_MS` configuration for exponential backoff
   ```yaml
   - RAG_RETRY_DELAY_MS=2000  # Start with 2s delay between retries
   ```

## Summary of Changes

### Audio Processing Memory Optimization
- **Whisper Model**: base (140M) → tiny (39M) - 78% smaller
- **Decoding**: beam_size=5 → beam_size=1 - O(5x) memory reduction  
- **Voice Activity**: Added VAD filter to skip silence and process only speech
- **Memory Management**: Explicit cleanup with `gc.collect()` and batch processing
- **Expected Memory Usage**: ~300-400MB (down from 800MB-1GB)

### Timeout & Retry Configuration
```yaml
RAG_TIMEOUT: 180000ms (3 minutes) - allows time for transcription
RAG_RETRY_DELAY_MS: 2000ms - exponential backoff (2s, 4s, 8s)
Health Check: Fixed path to /health/ with trailing slash
```

## Testing Recommendations

1. **Test with large audio file**:
   - Upload the 37MB MP3 file again
   - Monitor memory usage (should stay ~300-400MB during transcription)
   - Check that upload completes successfully within 3 minutes

2. **Monitor RAG logs**:
   - Verify Whisper loads "tiny" model, not "base"
   - Check that VAD filter is active
   - Confirm no OOM (Out of Memory) errors

3. **Verify response handling**:
   - Confirm final "complete" status is received and parsed
   - Check document_id is captured correctly
   - Verify chunk count is accurate

4. **Test health checks**:
   - Verify `/health/` endpoint returns 200 OK
   - Confirm no more 307 redirects
   - Check service stays healthy during file processing

## Expected Results

After these fixes:
1. ✅ Audio files should upload successfully without OOM crashes
2. ✅ Response should contain valid "complete" status with document_id
3. ✅ RAG service memory usage stays within container limits (~400MB)
4. ✅ Health checks properly report service status  
5. ✅ Document chunks should be viewable in the UI after successful upload
6. ✅ Processing completes in 2-3 minutes for 37MB audio files
